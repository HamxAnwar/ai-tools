### This file is general recommendations from ChatGPT 5 for which models to use ###


| Role         | Model                                     | Why                      |
| ------------ | ----------------------------------------- | ------------------------ |
| **Planner**  | DeepSeek-R1-Distill-7B                    | Better reasoning / plans |
| **Executor** | DeepSeekCoder V2 16B or Qwen2.5-Coder-14B | Better coding output     |

----------------------------------------------

model:
  provider: ollama
  model: deepseek-coder-v2:16b
  params:
    gpu_layers: 20
    offload_kv: true

----------------------------------------------

‚≠ê Best Overall for Tools (Local)

‚úî Qwen2.5-Coder-7B / 14B
‚úî DeepSeek Coder V2 16B
‚úî Llama 3.1/3.2 8B‚Äì11B
‚úî Phi-3.5 tools models (3.8B)

‚≠ê Best ‚ÄúPlanner‚Äù model:

‚úî DeepSeek-R1-Distill-7B
Extremely good at planning ‚Üí OpenCode tool sequences become better.

‚≠ê Best for multi-file diffs:

‚úî Qwen2.5-Coder
Structured output is strong ‚Üí follows tool JSON formatting more reliably.

----------------------------------------------

üü¶ Recommended stack for you (6GB VRAM)
Planner:

‚û°Ô∏è deepseek-r1-distill:7b
Great planning ‚Üí agent works properly.

Executor:

‚û°Ô∏è deepseek-coder-v2:16b
(OR qwen2.5-coder:14b if you want more stability)

---------------------------------------------

| Agent role          | Recommended model             | Change?     |
| ------------------- | ----------------------------- | ----------- |
| **Planner**         | DeepSeek-R1-Distill 7B or 14B | ‚ùå No change |
| **Builder / Coder** | Qwen2.5-Coder 14B             | ‚ùå No change |
